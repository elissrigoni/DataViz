---
title: "Text 12 June 2020"
output: html_notebook
---

**1. [0-5 points] Describe in detail the elements of visual encoding (marks and annotations), their meaning and their use. Explain and comment the meaning of the visual encoding elements in the following picture.**


```{r}
knitr::include_graphics("https://github.com/elissrigoni/DataViz/blob/2d5837ded0ef1a2f0c6de100af5ce8b2af73e516/Text_12Jun20/Ex1.jpg")
```
Reading a graph is the first sample data representation, whose steps are:

1. **Dataviz perception**: consists in decoding the elements of a graph (shapes, sizes, positions, colors).
2. **Dataviz interpretation**: consists in the decoding of the meaning of a graph, i.e. making sense of the overall graphic construction.

While talking about the developing of your design solution, data representation is one of the most important layer of the visualization design structure. A visualizer (the person in charge of creating visualizations) does the reverse process of decoding, which is decoding. Decoding consists in assigning visual properties to data values. And this is the basic of any data representation, along with the components that help completing the chart display.

There are different way to encode data, anyway data encoding is always a combination of marks and attributes. The way of getting the best data representation is finding the right blend of marks & attributes that most effectively portray the angle of analysis you wish to show.

* **Marks** are visibile features (e.g., dots, line and areas). An individual mark can represent a record of instance of data, but it can also represent an aggregation of records or instances. Kind of marks:
+ *point*: the point mark has no variation (is constant) in the spatial dimension. It is largely a placeholder commonly used to represent a quantity through position on a scale, forming the basis of, for example, *scatter plots*.
+ *line*: The line mark has one (linear) spatial dimension. It is commonly used to represent quantitative value through variation in size, forming the basis of, for example, the *bar chart*.
+ *area*: The area mark has two (quadratic) spatial dimensions. It is commonly used to represent quantitative values through variation in size and position, forming the basis of, for example, *bubble plots*.
+ *form*: The form mark has three (cubic) spatial dimensions. It might be used to represent quantitative values through variation in size (specifically through volume), forming the basis of, for example, a *3D proportional shape chart*.

* **Attributes** are variations applied to the appearence of marks, such as size, position, or color. They are used to represent the values held by different quantitative or categorical variables against each record, instance or aggregation. Kind of attributes:

1. **quantitative** ones:
+ *position*: position along a scale is used to indicate a quantitative value.
+ *size*: size (length, area, volume) is used to represent quantitative values based on proportional scales where the larger the size of the mark, the larger the quantity.
+ *angle/slope*: variation in the size of angle forms the basis of *pie chart* sectors representing parts-of-a-whole quantitative values; the larger the angle, the larger the proportion. The slope of an incline formed by angle variation can also be used to encode values.
+ *quantity*: the quantity of a repeated set of point marks can be used to represent a one-to-one or a one-to-may unit count.
+ *color saturation*: it can be used (often in conjunction with other color properties) to represent quantitative scales, tipically the greater the saturation, the higher the quantity.
+ *color lightness*: it can be used (often in conjunction with other color properties) to represent qualitative scales, typically the larger the color, the higher the quantity.
+ *pattern*: variation in pattern density or difference in pattern texture can be used to represent quantitative scales or distinguish between categorical ordinal states.
+ *motion*: motion is more rarely seen but i could be used as a binary indicator to draw focus (motion vs no motion) or by incorporating movement through speed and direction to represent a quantitative scale ramp.

2. **Categorical** ones:
+ *symbol/shape*: symbols or shapes are generally used with points markers to indicate categorical associations.
+ *color hue*: it is typically used for distinguishing different categorical data values, but can also be used in conjunction with other color properties to represent certain quantitative scales.

3. **Relational** attributes:
+ *connection/edge*: A connection or edge indicates a relationship between two nodes. Sometimes arrows may be added to indicate direction of relationship, but largerly it is just about the presence or absence of a connection.
+ *containment*: containment is a way of indicating a grouping relationship between categories that belong to a related hierarchical parent category.


**In the specific case of the provided plot:**
This is a **time series scatterplot**. In scatterplots every sample is represented by a dot. It is very useful when you have to display have large variations within range or to display the dispersion of the sample in the space. It is particularly useful to immediately detect trends, clusters and empty areas. Since there could be many points represented, it is suggested to pay attention to labels and annotations, that should be added only for noteworthy points (avoid to insert many elements in the plane). Use transparency when points are overlapping and pay attention to the ratio of the axis (since manipulating this ratio may affect the overall meaning of the graph itself by compressing or spreading points).

In this particular case, each dot is a **point mark** that represents the percentage in a given moment of time for a certain politician during 2012 general elections. So, each circle represent an opinion poll (expressed as a percentage in the y axis) from a certain source for a specific candidate in a specific moment of time (x axis). 

- position of the dots  represent the quantitative value in the percentage scale 
- different color hue is used to distinguish the two candidates (categorical attribute). 

The lines are **line marks**, that represent the trend of the percentage obtained respectively from each of the two candidates. The variation of the lines represent the change of a certain quantitative value (percentage). Another attribute is the color hue that, paired with the one used for the dots, associated to the same candidates. The two trendlines portray a certain statistic based on the actual values given by the opinion polls (the dots). So, the two lines give a summing up perception of the trends of preference for the two candidates over time.

**2. [0-5 points] Describe the step "Editorial Choices" in the Stage 3 of the Data Visualization Workflow; then provide 3 data visualization examples (not those in the lecture slides) to highlight focus, framing and angle concepts, respectively.**

STAGE 3 of the Data Workflow consists in ESTABLISHING EDITORIAL THINKING. The essence of editorial thinking is demonstrating a discerning eye for what you are going to portray visually to the audience. It concerns the choice of which of the many viable perspectives offered by data you will focus on:

1. **Angle**: Choosing an angle consists in selecting one or more viewpoint(s) in the analysis and in the representation of data, but also choose in which dimension you want to split all the subject. As it is in photography, in visualization you cannot show everything at once. A 360° view is impossible to display, and for sure not in a single chart, for this reason you have to pick an angle. In visualization, it refers to the angle of analysis you intend to show (e.g., what are you measuring and by which dimension are you breaking it down; are you going to show product sales over time, how are they organised by regions, or how they compare on a map and over time?). Also, using multiple charts you could portray different angles. When thinking to an angle to choose you should consider if it is:

**relevant**, understand the reason why you want to choose this angle/point of view and if it is worth showing to this audience. The key is finding a duality between normal and exceptional and to not choose a viewpoint hoping for someone to find the relevance, because when representing data, YOU should be aware of the relevance. Why is it worth to show your data from this angle and not another one? why this angle is going to offer the most relevant window into the subject for your intended audience? While thinking at relevance you should think about: 

+ *what does your intended audience want or need to know?* Often it is useful to refer to your audience's profile and the contextual circumstances. Sometimes it may be useful to create personas: a small number of imagined identities that may be demographically representative of the types of viewer you expect to target.
+ *What makes something relevant in your context?* You should consider whether relevance is a product of the normal or the exceptional. In fact, often the worthiness of an item of news is based on it being exceptional rather than going through the repeated reporting of normality. Do not hope that someone is going to find it relevant.
+ *What do you want your audience to know?* You should definitely take into account your audience's needs, but you might actually be better placed to determine what is truly relevant. Depending on the context, and on your proximity to the subject and its data, you might have the autonomy to decide what you want to say, more than what the audience want to see. In fact, audience may not know or not be sufficiently domain aware to determine what is relevant and what is not.
sufficient, this is about judging how many angles you need. 
+ *Is a chart offering a single angle into your data sufficient in regard of what you want to potray?* You cannot portray anything in one chart, maybe you need multiple charts offering multiple angles to sufficiently represent the most interesting dimension of the subject. Even in a small data set, it is pretty common to find yourself willing to show multiple angles and it is hard to ignore this temptation. But it is important to understand that throwing more and more angles in will automatically enrich your work. Finding just the right number of angles to show the core of your curiosity is the real art.

In addiction to that you have to ask yourself if they are **sufficient** to bring on the message, but keeping in mind that we do not need too many angles across space/time, doing an effective selection is important. 
+ *Is a chart offering a single angle into your data sufficient in regard of what you want to portray?* You cannot portray anything in one chart, maybe you need multiple charts offering multiple angles to sufficiently represent the most interesting dimension of the subject. Even in a small data set, it is pretty common to find yourself willing to show multiple angles and it is hard to ignore this temptation. But it is important to understand that throwing more and more angles in will automatically enrich your work. Finding just the right number of angles to show the core of your curiosity is the real art.
 
2. **Framing**: framing regards filtering which data to include or to exclude (remove unnecessary clutter because the presentation would be hard to read). Balance is an essential part, but thinking about how much content the audience can process is an important step. This is about the refinement of the angles you have selected (the field of view). 
+ *It is useful to ask yourself which data to include and to exclude: all category values or just a selection? All quantitative values or just those over a threshold? All data or just those between a defined start and end date period?* Answering to these questions is influenced by your trigger curiosity and also the complexity of the subject and the amount of data available. One key element of framing is to remove unnecessary clutter: there is only a certain quantity that can be fitted in a single view before it becomes too busy, too detailed and too small in resolution; also in the viewer's perspective there is just a limited quantity of content your audience will likely be willing and able to process. If you zoom-in, filtering away too much of the content might hide the important context required for perceiving values; on the other hand, if you avoid filtering your content you may fail to make visible the most salient discoveries.

* **Focus**: focus is needed to emphasis what is more important and provide a visual hierarchy and the reader should be able to understand what is more important. It consists in choosing fore-/mid-/back-ground, this can be done selecting size, color and location in an appropriate way. This is about what you might choose to focus on, rather than filtering, it is emphasizing what is more important in contrast to what is less important. Whereas framing were about reducing clutter, this is about reducing noise. Decisions about focus primarily concern the development of explanatory visualizations, because creating such a focus is a key purpose for that type of experience.


```{r}
url <- "https://flowingdata.com/wp-content/uploads/2021/03/GDP-and-vaccination-rates.png"
knitr::include_graphics(url)
```

**Angle**: the angle of analysis can be expressed as 'What is the relationship between vaccination rates and country wealth?'. According to Keith Collins and Josh Holder (authors of this visualization), this angle is relevant since they want to prove that vaccination rates and GDP per capita are strictly related. This angle is going to offer a relevant window into the subject (quite relevant in this period of time) and is easily interpretable from a wide range of readers. 

**Framing**: data taken into account for this visualization come from two different sources: the vaccination data from local governments via Our World in Data and income classifications and gross
domestic product data from the World Bank. The author decided to represent country wealth using GDP per capita as metric. It is necessary to specify that GDP per capita is an inadequate measure of development and well being, but it is usually used as an aggregate measure of production and gives information about the richness of a country. Another important variable included in the representation is the country population, portrayed as size of the 'bubbles' representing each country. Finally, data displayed are collected until April 1, 2021.  

**Focus**: The focus here is straightforward, author decided to group countries according to their wealth level: Low, Lower middle, Upper middle, High. This groups are well explained through a legend. Countries belonging to each group are well separated for different rates of vaccines received, with only few similar rates among countries from different groups. 
Moreover, a couple of annotations helps in the process of understanding, particularly during interpretation phase, while asking yourself about significance.
The message that the authors want to convey is that wealthier countries made deals with drug makers earlier, which means poorer countries are not able to secure as many vaccines.


**3. [0-5 points] Describe the MDS family of algorithms, and comment similarities and differences with PCA. Then explain the differences between Classical, Metric and Non-Metric MDS, and provide an example where only one of the three above choices is adequate.**

Multidimensional scaling is a family of algorithms visualizing the level of similarity of individual cases of a dataset. In practice, MDS finds an embedding of n objects into a r-dimensional euclidean space Rn so to preserve as well as possible the distances between original points. Usually is not possible to preserve the actual distances, but only a function of them. 

**Difference between PCA and non-metric MSD**
While PCA aims at describe the principal components (linear combinations) of a dataset that is able to explain the largest amount of variation, MDS, instead, aims at constructing a reduced dimensionality space so that the projected points preserve the mutual distances, inherited from the original dataset: the distance they have in the original dataset are - more or less - preserved in the projected space. When is this useful? In the case of objects of very different nature, for which there is no possible description in a feature space; examples of such cases are objects like drugs, images, trees or other complex objects without any obvious coordinates in . Despite that, a dissimilarity matrix can be constructed, that explains the mutual separation between these objects. Differently from PCA, MDS can produce some negative eigenvalues and this is due to the fact that the data do not come from a Euclidean space. MDS and PCA are probably not at the same level to be in line or opposite to each other. PCA is just a method while MDS is a class of analysis. As mapping, PCA is a particular case of MDS. On the other hand, PCA is a particular case of Factor analysis which, being a data reduction, is more than only a mapping, while MDS is only a mapping. PCA is the first algorithm that have been created. The idea is to decorrelate the original elements of a dataset, by decorrelating original elements, we can extract the single properties of each of them and after that it is possible to isolate the points that contain more information. The input to PCA is the original vectors in n-dimensional space. And the data are projected onto the directions in the data with the most variance. Hence the “spread” of the data is roughly conserved as the dimensionality decreases. On the other hand the input to MDS is the pairwise distances between points. The output of MDS is a two- or three-dimensional projection of the points where distances are preserved. MDS can be distinguished in 3 types, depending on the objective function:

* **classical MDS** - also known as Pricipal Coordinates Analysis (PCoA), the objective function is called strain and involves directly the original distances between objects. The solution is deterministic and the core of the dimensionality reduction is the same as PCA (changing the objective function). If there exists a space Rp where all the original distances between objects are preserved, the distance d is called euclidean; for an euclidean distance, the classical MDS solution is unique up to isometries (a rigid transformation of the space that conserve the distance, for instance rotation, symmetry…)

* **metric MDS** -  it is a superset of classical MDS, so that it generalizes the optimization procedure to other kind of loss functions. A popular function to minimize is called stress and it involves a function of the original distances. In metric mds we can find Sammon mapping that is able to preserve the small giving them a greater degree of importance in the fitting procedure that for larger . With respect to classical MDS, Sammon mapping better preserves inter-distances for smaler dissimilarities, while proportionally squeezes the inter-distances for larger dissimilarities.

* **non-metric MDS** – if we are not in a metric space the original distances are assessed as dissimilarities, so the stress function finds a non-parametric monotonic relationship between the dissimilarities in the item-item matrix and the Euclidean distances between items, and defines the location of each item. A common algorithm in non-metric MDS is Kruskal mds. In other words, it is possible to say that with non-metric MDS absolute values are not considered as meaningful, only the ranking is important, so that MDS tries to find a low-dimensional representation that respects the ranking of distances. Non-metric MDS Fulfills a clear objective without many assumptions (just minimize stress), results do not change with rescaling or monotonic variable transformation, it works even if starting just from ranking information. By the way, it is slow in large problems, usually it is able to found a local (not global) optimum. Non-metric MDS is widely used when dissimilarities are known only by their rank order, and the spacing between successively ranked dissimilarities is of no interest or is unavailable. f is implicitly defined as a regression curve, and only preserves the order of distance d, that is: $f(dij)<f(dkl)$ if $dij<dkl$ thus only the order of d is needed, not the actual values. (Most common algorithm is the Kruskal MDS.)
In metric and non-metric case, the process is given by optimization (deterministic solution is not feasible).

**A case when only non-metric MdS is adequate (with respect to the others kind of MdS)**
Non-metric MDS is iterative and non-parametric and allows one to use any distance measure that might be suitable for the data. It does not make any assumptions about a linear relationship. NMDS **arranges points to maximize rank-order correlation between real-world distance and ordination space distance**. Unlike PCA (which uses Eucliden distances), non-metric MDS relies on rank orders (distances) for ordination (i.e. non-metric).
In the case of a dissimilarity matrix, which is not a distance matrix, classical MDS gives inconsistents results. In these cases Non-metric MDS is highly suggested over classical MDS. To have a general theoretical grip: in all the cases/experiments in which an interobserver agreement (IOA) between people, instead of actual distances, is used in the construction of the dissimilarity matrix. As practical examples I would say The Ekman colors study and the perception of similarity between different sports.

**[0-7 points] Using the datafile economist_data.csv, prepare a chloroplet map of a geographical region of your choice (Europe, Asia, etc) displaying one (or more) of the columns HDI.Rank, HDI, CPI.** 

JUPYTER NOTEBOOK

```{r}
url <- "https://github.com/elissrigoni/DataViz/blob/main/Text_12Jun20/economist_data.csv"
```


**5. [0-7 points] Consider the dataset countries.csv : prepare a dimensionality reduction planar projection (using the method you rate as the most adequate), color the countries according to your preferred grouping and comment one or more facts emerging from the plot.**

JUPYTER NOTEBOOK
**6. [0-7 points] Using the datafile economist_data.csv, try to replicate the following plot, where Human Development Index is column HDI and Corruption Perception Index is column CPI; the red line can be a smoothing line of your choice.**

```{r}
# libraries
library(tidyverse)
library(ggplot2)
library(ggrepel)
library(grid)
```

 
```{r}
knitr::include_graphics("https://github.com/elissrigoni/DataViz/blob/80f8c10c213ce76512015feb8bb38d04a0c7a5b5/Text_12Jun20/economist_data.png")
```

```{r}
dat <- read_csv("https://databeauty.com/data/EconomistData.csv")
dat$Country <- as.factor(dat$Country)
dat
```

```{r}
# Data preprocessing
points_to_label <- c("Russia", "Venezuela", "Iraq", "Sudan", "Congo", "Greece", "Argentina", "Brazil", "India", "Italy", "China", "Buthan", "France", "United States", "Germany", "Britain", "Norway", "Japan")

sub_data <- subset(dat, Country %in% points_to_label)
# consider modified data 
dat$Region <- factor(dat$Region, levels = c("EU W. Europe", "Americas", "Asia Pacific", "East EU Cemt Asia", "MENA", "SSA"), 
                     labels = c("OECD", "Americas", "Asia &Oceania", "Central & Eastern Europe", 
                                "Middle East & North Africa", "Sub-Saharan Africa"))

```


```{r}
# Scatterplot
gg <- ggplot(dat, aes(x = CPI, y = HDI)) +
  geom_smooth(aes(group=1), method="lm", formula = y~log(x), se=F, col = "red3", lwd = 0.8) + 
  geom_point(aes(col=Region), shape=1, size = 3) + 
  labs(title="Corruption and human development") +
  theme(title.position = "top") +
  
  # scale axis
  scale_x_continuous(name = expression(italic("Corruption Perceptions Index, 2011 (10 = least corrupt)")), 
                     limits = c(0.9, 10.2), breaks = 1:10) + 
  scale_y_continuous(name = expression(italic("Human Development Index, 2011 (1 = best)")), 
                     limits = c(0.15, 1), breaks = seq(0, 1, 0.1)) +

  geom_text_repel(aes(label = Country), color = "gray20", data = sub_data, force = 20) +
                                                                           #manage distance 
  # aesthetic
  theme_minimal()+
  theme(text = element_text(color ="gray10"),
        #legend
        legend.position = "top",
        legend.direction = "horizontal",
        legend.justification = "right",
        legend.text = element_text(size = 11, color = "gray10"),
        legend.title = element_blank(),
        
        # axis text
        axis.text = element_text(face = "italic"),
        
         # move axis away from the graph
        axis.title.x = element_text(vjust = -1),
        axis.title.y = element_text(vjust = 2), 
        axis.line.y = element_blank(),
        # add lower righello
        axis.line = element_line(color = "gray40", size = 0.5),
        panel.grid.minor=element_blank(),
        panel.grid.major = element_line(color = "gray40", size = 0.5),
        panel.grid.major.x = element_blank()) 
       
        
gg
```


```{r}
# add R2 value on the legend
R2 <- summary(lm(HDI ~ log(CPI), data = dat))$r.squared
#png(file = "economist_reprod.png", width = 800, height = 600)
# add on the legend using grid
gg

# ADD R2
grid.segments(x0=0.185, x1 = 0.205, y0 = 0.88, y1=0.88, gp = gpar(col = "red3"))
grid.text(paste0("linetype     r2"), x = 0.1, y = 0.885, gp = gpar(col = "gray20"), draw = T, just = "left")

```


